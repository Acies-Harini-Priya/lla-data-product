version: v1
name: ingestion-masterdata-lla
type: workflow
tags:
  - ingestion-masterdata-lla # to find this ingestion in metis
description: This job read data from to postgres
title: Read Postgres
workflow:
  dag:
    - name: ingestion-masterdata-lla
      title: Read Postgres
      description: This job read data from postgres
      spec:
        tags:
          - ingestion-masterdata-lla
        stack: flare:5.0
        compute: runnable-default

        stackSpec:
          job:
            explain: true

            inputs:
              - name: master_data
                dataset: dataos://modempg:public/modem_info?acl=rw # once the depot cmd is run successfully, search for this depotname in metis to find this link
                options:
                  driver: org.postgresql.Driver # default driver for postrges
            logLevel: INFO
          
            outputs:
              - name: output
                dataset: dataos://lakehouse:sru/master_data  # Here we are using already created lakehouse, but in real-time create a lakehouse and get this link from metis
                format: Iceberg
                options:
                  saveMode: overwrite
                description: Data set from blender
                tags:
                  - Connect
                title: Postgres Dataset

            steps:
              - sequence:
                  - name: output # name in outputs (where we point to the lakehouse -> dataset is going to be stored in this location) 
                    sql: SELECT CAST(to_timestamp(timestamp, 'M/d/yyyy H:mm') AS TIMESTAMP) as timestamp , modem_id FROM master_data  
                    functions:
                      - name: cleanse_column_names
                      - name: change_column_case
                        case: lower

                    # From table has to be the name in inputs (where we point to the depot)